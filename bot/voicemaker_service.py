"""
Module for handling VoiceMaker TTS API interactions.
"""

import os
import logging
import tempfile
import time
import requests
from pathlib import Path
from typing import List, Tuple, Optional, Dict
from pydub import AudioSegment
from bot.db.user_service import get_user_audio_speed, get_user_background_effects
from bot.languages import get_language_config

logger = logging.getLogger(__name__)

# VoiceMaker API endpoints
VOICEMAKER_API_URL = "https://developer.voicemaker.in/voice/api"
VOICEMAKER_VOXFX_API_URL = "https://developer.voicemaker.in/api/v1/voice/convert"

# Language code mapping for VoiceMaker
LANGUAGE_CODE_MAP = {
    "is": "is-IS",  # Icelandic
    "de": "de-DE",  # German
    "en": "en-US",  # English (default)
}

# Engine mapping based on voice prefix
ENGINE_MAP = {
    "ai3": "neural",
    "ai2": "neural",
    "pro1": "neural",
    "standard": "standard",
}

# All available VoxFX presets
# Key is the preset ID, value contains name, emoji, and default dryWet
VOXFX_PRESETS = {
    "train_station": {
        "presetId": "67841788096cecfe8b18b2d5",
        "name": "Train Station",
        "emoji": "ðŸš‚",
        "dryWet": 40,
    },
    "airport": {
        "presetId": "67841788096cecfe8b18b2d3",
        "name": "Airport Announcement",
        "emoji": "âœˆï¸",
        "dryWet": 50,
    },
    "subway": {
        "presetId": "67841788096cecfe8b18b2d7",
        "name": "Subway Train Inside",
        "emoji": "ðŸš‡",
        "dryWet": 50,
    },
    "poor_signal": {
        "presetId": "67841788096cecfe8b18b2f7",
        "name": "Poor Signal",
        "emoji": "ðŸ“¡",
        "dryWet": 60,
    },
    "coffee_shop": {
        "presetId": "67841788096cecfe8b18b2e9",  # TODO: Verify this preset ID
        "name": "Coffee Shop",
        "emoji": "â˜•",
        "dryWet": 40,
    },
    "shopping_mall": {
        "presetId": "67841788096cecfe8b18b2eb",  # TODO: Verify this preset ID
        "name": "Shopping Mall",
        "emoji": "ðŸ›’",
        "dryWet": 45,
    },
}

# VoxFX preset mapping by CEFR level (for "auto" mode)
# Lower levels = cleaner audio, higher levels = more challenging listening conditions
VOXFX_PRESETS_BY_LEVEL = {
    "A1": None,  # No effects - clear audio for beginners
    "A2": None,  # No effects - clear audio for elementary
    "B1": "train_station",
    "B2": "airport",
    "C1": "subway",
    "C2": "poor_signal",
}


class VoiceMakerService:
    """Service for generating TTS audio using VoiceMaker API."""

    def __init__(self):
        """Initialize VoiceMaker client using API key from environment variables."""
        self.api_key = os.environ.get("VOICEMAKER_API_KEY")
        if not self.api_key:
            raise ValueError("VOICEMAKER_API_KEY environment variable is not set")

        # Retry configuration
        self.max_retries = 3
        self.base_delay = 2  # seconds

        logger.info("VoiceMaker TTS service initialized")

    def _get_engine_from_voice(self, voice_id: str) -> str:
        """Determine the engine type from voice ID prefix."""
        for prefix, engine in ENGINE_MAP.items():
            if voice_id.startswith(prefix):
                return engine
        return "neural"  # default

    def _generate_single_audio(
        self,
        text: str,
        voice_id: str,
        language_code: str,
        speed: int = 0,
        voxfx: Optional[Dict] = None,
    ) -> bytes:
        """
        Generate audio for a single text using VoiceMaker API.

        Args:
            text: Text to convert to speech
            voice_id: VoiceMaker voice ID (e.g., "ai3-is-IS-Svana")
            language_code: Language code (e.g., "is-IS")
            speed: Speed adjustment (-100 to 100), default 0
            voxfx: Optional VoxFX preset configuration for background effects

        Returns:
            Audio data as bytes

        Raises:
            Exception: If API call fails after retries
        """
        engine = self._get_engine_from_voice(voice_id)

        payload = {
            "Engine": engine,
            "VoiceId": voice_id,
            "LanguageCode": language_code,
            "Text": text,
            "OutputFormat": "mp3",
            "SampleRate": "48000",
            "Effect": "default",
            "MasterVolume": "0",
            "MasterSpeed": str(speed),
            "MasterPitch": "0",
        }

        # Determine which API endpoint to use
        # VoxFX effects require the /api/v1/voice/convert endpoint
        if voxfx:
            api_url = VOICEMAKER_VOXFX_API_URL
            payload["VoxFx"] = voxfx
            logger.info(
                f"Using VoxFX endpoint with preset: {voxfx['presetId']}, dryWet: {voxfx['dryWet']}"
            )
        else:
            api_url = VOICEMAKER_API_URL

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        last_error = None
        for retry in range(self.max_retries):
            try:
                logger.debug(
                    f"Sending TTS request to VoiceMaker: voice={voice_id}, text='{text[:50]}...'"
                )

                response = requests.post(
                    api_url,
                    json=payload,
                    headers=headers,
                    timeout=60,
                )

                response.raise_for_status()
                result = response.json()

                if not result.get("success"):
                    error_msg = result.get("message", "Unknown error")
                    raise Exception(f"VoiceMaker API error: {error_msg}")

                # Download the audio file
                audio_url = result.get("path")
                if not audio_url:
                    raise Exception("VoiceMaker API did not return audio URL")

                logger.debug(f"Downloading audio from: {audio_url}")
                audio_response = requests.get(audio_url, timeout=60)
                audio_response.raise_for_status()

                logger.debug(
                    f"Successfully generated {len(audio_response.content)} bytes of audio"
                )
                return audio_response.content

            except requests.exceptions.RequestException as e:
                last_error = e
                if retry < self.max_retries - 1:
                    delay = self.base_delay * (2**retry)
                    logger.warning(
                        f"VoiceMaker request failed (attempt {retry + 1}/{self.max_retries}): {e}. "
                        f"Retrying in {delay}s..."
                    )
                    time.sleep(delay)
                    continue
                raise

            except Exception as e:
                last_error = e
                logger.error(f"VoiceMaker API error: {e}")
                raise

        raise last_error

    def generate_audio_for_dialogue(
        self,
        dialogue_lines: List[Tuple[str, str]],
        user_id: Optional[int] = None,
        lang_config=None,
        language_level: str = "A2",
    ) -> str:
        """
        Generate audio files for each line in the dialogue and merge them into a single file.

        Args:
            dialogue_lines: List of (speaker, text) tuples
            user_id: Telegram user ID to get audio speed settings (optional)
            lang_config: Language configuration (optional, defaults to TARGET_LANGUAGE config)
            language_level: CEFR language level for VoxFX effects (default: A2)

        Returns:
            Path to the generated audio file
        """
        if lang_config is None:
            lang_config = get_language_config()

        logger.info(
            f"Generating audio for {len(dialogue_lines)} dialogue lines using VoiceMaker"
        )
        temp_dir = tempfile.mkdtemp()
        logger.debug(f"Created temporary directory: {temp_dir}")
        temp_files = []

        # Get user's audio speed if user_id is provided
        user_audio_speed = 1.0  # Default speed
        background_effects_setting = "off"
        if user_id:
            user_audio_speed = get_user_audio_speed(user_id)
            background_effects_setting = get_user_background_effects(user_id)
            logger.info(f"Using audio speed {user_audio_speed} for user {user_id}")
            logger.info(f"Background effects setting: {background_effects_setting}")

        # Get VoxFX preset based on user setting
        voxfx_preset = None
        if background_effects_setting == "off":
            logger.info("Background effects disabled (off)")
        elif background_effects_setting == "auto":
            # Auto mode: select preset based on CEFR level
            preset_key = VOXFX_PRESETS_BY_LEVEL.get(language_level)
            if preset_key and preset_key in VOXFX_PRESETS:
                preset_data = VOXFX_PRESETS[preset_key]
                voxfx_preset = {
                    "presetId": preset_data["presetId"],
                    "dryWet": preset_data["dryWet"],
                }
                logger.info(
                    f"Auto mode: using VoxFX preset '{preset_key}' for {language_level} level"
                )
            else:
                logger.info(
                    f"Auto mode: no VoxFX preset for {language_level} level (clean audio)"
                )
        elif background_effects_setting in VOXFX_PRESETS:
            # Specific preset selected
            preset_data = VOXFX_PRESETS[background_effects_setting]
            voxfx_preset = {
                "presetId": preset_data["presetId"],
                "dryWet": preset_data["dryWet"],
            }
            logger.info(
                f"Using user-selected VoxFX preset: {background_effects_setting}"
            )
        else:
            logger.warning(
                f"Unknown background effects setting: {background_effects_setting}, using no effects"
            )

        # Convert speed to VoiceMaker format (-100 to 100)
        # user_audio_speed is typically 0.5 to 2.0, where 1.0 is normal
        # VoiceMaker uses -100 (slowest) to 100 (fastest), 0 is normal
        voicemaker_speed = int((user_audio_speed - 1.0) * 100)
        voicemaker_speed = max(-100, min(100, voicemaker_speed))  # Clamp to valid range

        # Get voice settings from language config
        voice_settings = lang_config.get_voice_settings(user_audio_speed)

        # Get language code for VoiceMaker
        language_code = LANGUAGE_CODE_MAP.get(lang_config.code, "en-US")

        try:
            # Generate individual audio files for each line
            female_label = lang_config.speakers["female"].label
            for i, (speaker, text) in enumerate(dialogue_lines):
                # Get voice settings based on speaker
                settings = voice_settings.get(speaker, voice_settings[female_label])
                voice_id = settings["voice"]

                logger.info(
                    f"Generating audio for line {i + 1}: {speaker} - '{text[:30]}...' using voice '{voice_id}'"
                )

                file_path = os.path.join(temp_dir, f"part_{i}.mp3")

                try:
                    audio_data = self._generate_single_audio(
                        text=text,
                        voice_id=voice_id,
                        language_code=language_code,
                        speed=voicemaker_speed,
                        voxfx=voxfx_preset,
                    )

                    with open(file_path, "wb") as f:
                        f.write(audio_data)

                    logger.debug(f"Audio file created: {file_path}")
                    temp_files.append(file_path)

                except Exception as e:
                    logger.error(f"Error generating audio for line {i + 1}: {e}")
                    raise

            # Merge audio files
            logger.info("Merging individual audio files")
            merged_audio = AudioSegment.empty()
            for i, file_path in enumerate(temp_files):
                logger.debug(
                    f"Adding audio file {i + 1}/{len(temp_files)} to merged audio"
                )
                audio_segment = AudioSegment.from_file(file_path)
                merged_audio += audio_segment

                # Add a small pause between lines
                pause = AudioSegment.silent(duration=500)  # 500ms pause
                merged_audio += pause

            # Save the merged audio
            output_path = os.path.join(temp_dir, "dialogue.mp3")
            logger.info(f"Exporting merged audio to {output_path}")
            merged_audio.export(output_path, format="mp3")

            # Move to a more permanent location
            final_path = Path(__file__).parent.parent / "data"
            final_path.mkdir(exist_ok=True)
            final_file = final_path / "section_01_dialogue.mp3"

            logger.info(f"Copying audio file to final location: {final_file}")
            with open(output_path, "rb") as src, open(final_file, "wb") as dst:
                dst.write(src.read())

            logger.info(f"Audio generation complete: {final_file}")
            return str(final_file)

        except Exception as e:
            logger.error(f"Error in audio generation process: {e}")
            raise


# Singleton instance
_voicemaker_service: Optional[VoiceMakerService] = None


def get_voicemaker_service() -> VoiceMakerService:
    """Get or create the VoiceMaker service singleton."""
    global _voicemaker_service
    if _voicemaker_service is None:
        _voicemaker_service = VoiceMakerService()
    return _voicemaker_service
